{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp utils.imports.common_voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-23 14:35:43.939268: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import os, sys\n",
    "import shutil\n",
    "import multiprocessing\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import ffmpeg\n",
    "import json\n",
    "\n",
    "from typing import TextIO\n",
    "\n",
    "import audioengine\n",
    "from audioengine.utils.schema import verify_audioengine_dataset\n",
    "from audioengine.utils.misc import (log_init, log_error, log_info, log_debug,\n",
    "                                    change_file_extension, get_json_file_integrity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is not to be exported\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Logging now set to file: /project/Development/ML/audio/logs/audioengine.log with level DEBUG\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_646377/2445500010.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtrain_test_val_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_test_val_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain_test_val_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain_test_val_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_output_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DEBUG = True \n",
    "\n",
    "if DEBUG:\n",
    "    log_init()\n",
    "    dataset_output_location = '/project/Datasets/audioengine_single_word'\n",
    "    dataset_input_location = '/project/Datasets/common_voice_single_word'\n",
    "    dataset_audio_clips_directory = 'clips'\n",
    "    #dataset_name = 'dev.tsv'\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_dataset_name = 'train.tsv'\n",
    "    test_dataset_name = 'test.tsv'\n",
    "    val_dataset_name = ''\n",
    "    \n",
    "    generate_train_dataset = True\n",
    "    generate_test_dataset = True\n",
    "    generate_validation_dataset = True\n",
    "    \n",
    "    train_test_val_split = (0.7, 0.2, 0.1)\n",
    "    \n",
    "    assert(train_test_val_split[0] + train_test_val_split[1] + train_test_val_split[2] == 1.0)\n",
    "    \n",
    "    if(os.path.isdir(dataset_output_location)):\n",
    "        shutil.rmtree(dataset_output_location)\n",
    "    else:\n",
    "        pass\n",
    "    os.mkdir(dataset_output_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def read_tsv(tsv_filepointer: TextIO) -> pd.DataFrame:\n",
    "    \"\"\"The input filepointer should already be open with no lines read\"\"\"\n",
    "    tsv_data_df = pd.read_csv(tsv_filepointer, sep = '\\t')\n",
    "    return tsv_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def delete_pandas_columns(df: pd.DataFrame, column_list: list) -> pd.DataFrame:\n",
    "    for column in column_list:\n",
    "        del df[column]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:    \n",
    "    frames = []\n",
    "    if(train_dataset_name != ''):\n",
    "        common_voice_train_filepath = os.path.join(dataset_input_location, train_dataset_name)\n",
    "        common_voice_train_filepointer = open(common_voice_train_filepath, 'r')\n",
    "        common_voice_train_df = read_tsv(common_voice_train_filepointer)\n",
    "        frames.append(common_voice_train_df)\n",
    "    elif(generate_train_dataset):\n",
    "        train_dataset_name = 'train.json'\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if(test_dataset_name != ''):\n",
    "        common_voice_test_filepath = os.path.join(dataset_input_location, test_dataset_name)\n",
    "        common_voice_test_filepointer = open(common_voice_test_filepath, 'r')\n",
    "        common_voice_test_df = read_tsv(common_voice_test_filepointer)\n",
    "        frames.append(common_voice_test_df)\n",
    "    elif(generate_test_dataset):\n",
    "        test_dataset_name = 'test.json'\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if(val_dataset_name != ''):\n",
    "        common_voice_val_filepath = os.path.join(dataset_input_location, val_dataset_name)\n",
    "        common_voice_val_filepointer = open(common_voice_val_filepath, 'r')\n",
    "        common_voice_val_df = read_tsv(common_voice_val_filepointer)\n",
    "        frames.append(common_voice_val_df)\n",
    "    elif(generate_validation_dataset):\n",
    "        val_dataset_name = 'val.json'\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if(frames == []):\n",
    "        log_critical('No input files to convert')\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    common_voice_df = pd.concat(frames)\n",
    "    drop_columns = ['age', 'gender', 'accent', 'locale', 'segment', 'up_votes', 'down_votes', 'client_id']\n",
    "    \n",
    "    if(generate_train_dataset):\n",
    "        #Generate the train set\n",
    "        train_set_size = math.floor(train_test_val_split[0] * len(common_voice_df))\n",
    "        if(train_set_size < 1):\n",
    "            log_error('Size of train set less than one')\n",
    "            sys.exit(1)\n",
    "        else:\n",
    "            pass\n",
    "        common_voice_train_df = common_voice_df[0:train_set_size]\n",
    "        common_voice_df[train_set_size:]\n",
    "        common_voice_train_df = delete_pandas_columns(common_voice_train_df, drop_columns)\n",
    "    else:\n",
    "        pass\n",
    "    if(generate_test_dataset):\n",
    "        #Generate the test set\n",
    "        test_val_split = (train_test_val_split[1], train_test_val_split[2])\n",
    "        new_train_percentage = test_val_split[0] / (test_val_split[0] + test_val_split[1])\n",
    "        test_set_size = math.floor(test_val_split[0] * len(common_voice_df))\n",
    "        if(train_set_size < 1):\n",
    "            log_error('Size of test set less than one')\n",
    "            sys.exit(1)\n",
    "        else:\n",
    "            pass\n",
    "        common_voice_test_df = common_voice_df[0:test_set_size]\n",
    "        common_voice_df = common_voice_df[test_set_size:]\n",
    "        common_voice_test_df = delete_pandas_columns(common_voice_test_df, drop_columns)\n",
    "    else:\n",
    "        pass\n",
    "    if(generate_validation_dataset):\n",
    "        #Assign the val set\n",
    "        if(len(common_voice_df) < 1):\n",
    "            log_error('Zero length val dataset')\n",
    "            sys.exit(1)\n",
    "        else:\n",
    "            pass\n",
    "        common_voice_val_df = common_voice_df #By this point the rest of the df has already been taken for training or test\n",
    "        common_voice_val_df = delete_pandas_columns(common_voice_val_df, drop_columns)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    display(common_voice_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df_to_audioengine_label(df: pd.DataFrame, path_column_name: str, label_column_name: str) -> dict:\n",
    "    audio_data_json = {}\n",
    "    categories = []\n",
    "    categories_id_map = {}\n",
    "    categories_json_list = []\n",
    "    audio_json_list = []\n",
    "    for i, v in df.iterrows():\n",
    "        old_filename = v[path_column_name]\n",
    "        filename = change_file_extension(old_filename, '.wav')\n",
    "        \n",
    "        label = v[label_column_name]\n",
    "        if(label not in categories):\n",
    "            categories.append(label)\n",
    "            categories_id_map[label] = len(categories)\n",
    "            categories_json = {'id': len(categories),\n",
    "                              'name': label,\n",
    "                              'supercategory': 'Word'}\n",
    "            categories_json_list.append(categories_json.copy())\n",
    "        else:\n",
    "            pass\n",
    "        category_id = categories_id_map[label]\n",
    "        audio_json = {'id': i,\n",
    "                     'category_id': category_id,\n",
    "                     'file_name': filename}\n",
    "        audio_json_list.append(audio_json.copy())\n",
    "    licenses_json = {\n",
    "        'id': 1,\n",
    "        'name': 'CC0',\n",
    "        'url': 'https://creativecommons.org/share-your-work/public-domain/cc0/'\n",
    "    }\n",
    "    info_json = {\n",
    "        'year': 2021,\n",
    "        'version': '1.0',\n",
    "        'description': 'Mozilla single word dataset',\n",
    "        'contributor': 'Mozilla and contributors',\n",
    "        'url': 'https://commonvoice.mozilla.org/en',\n",
    "        'date_created': '2021-06-30',\n",
    "        'task': 'classification',\n",
    "    }\n",
    "    audioengine_dataset = {'info': info_json,\n",
    "                          'licenses': [licenses_json],\n",
    "                          'audio': audio_json_list,\n",
    "                          'categories': categories_json_list}\n",
    "    return audioengine_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    if(generate_train_dataset):\n",
    "        audioengine_train_json = convert_df_to_audioengine_label(common_voice_train_df, 'path', 'sentence')\n",
    "        if(not verify_audioengine_dataset(audioengine_train_json)):\n",
    "            log_error('The common voice import failed because the audioengine_json did not match the audioengine_dataset schema')\n",
    "        else:\n",
    "            log_info('Success the common voice descriptor file has successfully been converted into the audioengine JSON format')\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if(generate_test_dataset):\n",
    "        audioengine_test_json = convert_df_to_audioengine_label(common_voice_test_df, 'path', 'sentence')\n",
    "        if(not verify_audioengine_dataset(audioengine_test_json)):\n",
    "            log_error('The common voice import failed because the audioengine_json did not match the audioengine_dataset schema')\n",
    "        else:\n",
    "            log_info('Success the common voice descriptor file has successfully been converted into the audioengine JSON format')\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if(generate_validation_dataset):\n",
    "        audioengine_val_json = convert_df_to_audioengine_label(common_voice_val_df, 'path', 'sentence')\n",
    "        if(not verify_audioengine_dataset(audioengine_val_json)):\n",
    "            log_error('The common voice import failed because the audioengine_json did not match the audioengine_dataset schema')\n",
    "        else:\n",
    "            log_info('Success the common voice descriptor file has successfully been converted into the audioengine JSON format')\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_audio_file_to_wav(in_filename: str, out_filename: str) -> bool:\n",
    "    if(os.path.isfile(in_filename)):\n",
    "        if(os.path.isfile(out_filename)):\n",
    "            return True #File exists\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        ffmpeg.output(ffmpeg.input(in_filename), out_filename).run()\n",
    "        if(os.path.isfile(out_filename)):\n",
    "            return True\n",
    "        else:\n",
    "            log_error('Failed to convert {} to {}'.format(in_filename, out_filename))\n",
    "            return False\n",
    "    else:\n",
    "        log_error('Failed to convert {} file does not exist'.format(in_filename))\n",
    "        return False\n",
    "    return False\n",
    "\n",
    "def convert_audio_file_to_wav_multiprocessing_wrapper(filepath: dict) -> bool:\n",
    "    return convert_audio_file_to_wav(filepath['old'], filepath['new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiprocess_convert_files_to_wav(df: pd.DataFrame, \n",
    "                                      path_column_name: str, \n",
    "                                      old_directory: str,\n",
    "                                      new_directory: str,\n",
    "                                      num_cores: int=0) -> list:\n",
    "    if(num_cores<=0):\n",
    "        num_cores = (math.floor(multiprocessing.cpu_count() * 0.9) if math.floor(multiprocessing.cpu_count() * 0.9) >= 1 else 1) \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    filepaths = []\n",
    "    for i, v in df.iterrows():\n",
    "        old_filename = v[path_column_name]\n",
    "        new_filename = change_file_extension(old_filename, '.wav')\n",
    "        \n",
    "        old_filepath = os.path.join(old_directory, old_filename)\n",
    "        new_filepath = os.path.join(new_directory, new_filename)\n",
    "        filepath_json = {'old': old_filepath, 'new': new_filepath}\n",
    "        filepaths.append(filepath_json.copy())\n",
    "    \n",
    "    success_list = []\n",
    "    \n",
    "    if(not os.path.isdir(new_directory)):\n",
    "        os.mkdir(new_directory)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    with multiprocessing.Pool(processes=num_cores) as pool:\n",
    "        for success in pool.imap_unordered(convert_audio_file_to_wav_multiprocessing_wrapper, filepaths):\n",
    "            success_list.append(success)\n",
    "        pool.close()\n",
    "    return success_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    input_clips_path = os.path.join(dataset_input_location, dataset_audio_clips_directory) \n",
    "    output_clips_path = os.path.join(dataset_output_location, dataset_audio_clips_directory)\n",
    "    if(generate_train_dataset):\n",
    "        multiprocess_convert_files_to_wav(common_voice_train_df, 'path', input_clips_path, output_clips_path)\n",
    "    else:\n",
    "        pass\n",
    "    if(generate_test_dataset):\n",
    "        multiprocess_convert_files_to_wav(common_voice_test_df, 'path', input_clips_path, output_clips_path)\n",
    "    else:\n",
    "        pass\n",
    "    if(generate_validation_dataset):\n",
    "        multiprocess_convert_files_to_wav(common_voice_val_df, 'path', input_clips_path, output_clips_path)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    if(generate_train_dataset):\n",
    "        new_train_dataset_filename = change_file_extension(train_dataset_name, '.json')\n",
    "        new_train_dataset_filepath = os.path.join(dataset_output_location, new_train_dataset_filename)\n",
    "\n",
    "        audioengine_train_file = open(new_train_dataset_filepath, 'w')\n",
    "        json.dump(audioengine_train_json, audioengine_train_file, indent = 4)\n",
    "        audioengine_train_file.close()\n",
    "\n",
    "        if(get_json_file_integrity(audioengine_train_json, new_train_dataset_filepath) == False):\n",
    "            log_error('The JSON in the file {} does not match the json in memory'.format(new_train_dataset_filename))\n",
    "        else:\n",
    "            log_debug('|VALID| The JSON in the file {} matches the version in memory'.format(new_train_dataset_filename))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if(generate_test_dataset):\n",
    "        new_test_dataset_filename = change_file_extension(test_dataset_name, '.json')\n",
    "        new_test_dataset_filepath = os.path.join(dataset_output_location, new_test_dataset_filename)\n",
    "\n",
    "        audioengine_test_file = open(new_test_dataset_filepath, 'w')\n",
    "        json.dump(audioengine_test_json, audioengine_test_file, indent = 4)\n",
    "        audioengine_test_file.close()\n",
    "\n",
    "        if(get_json_file_integrity(audioengine_test_json, new_test_dataset_filepath) == False):\n",
    "            log_error('The JSON in the file {} does not match the json in memory'.format(new_test_dataset_filename))\n",
    "        else:\n",
    "            log_debug('|VALID| The JSON in the file {} matches the version in memory'.format(new_test_dataset_filename))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if(generate_validation_dataset):\n",
    "        new_val_dataset_filename = change_file_extension(val_dataset_name, '.json')\n",
    "        new_val_dataset_filepath = os.path.join(dataset_output_location, new_val_dataset_filename)\n",
    "\n",
    "        audioengine_val_file = open(new_val_dataset_filepath, 'w')\n",
    "        json.dump(audioengine_val_json, audioengine_val_file, indent = 4)\n",
    "        audioengine_val_file.close()\n",
    "\n",
    "        if(get_json_file_integrity(audioengine_val_json, new_val_dataset_filepath) == False):\n",
    "            log_error('The JSON in the file {} does not match the json in memory'.format(new_val_dataset_filename))\n",
    "        else:\n",
    "            log_debug('|VALID| The JSON in the file {} matches the version in memory'.format(new_val_dataset_filename))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
