{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class SimpleFeedForwardNetwork5(tf.keras.Model):\n",
    "    def __init__(self, num_classes: int = 0, input_length: int = 0, **kwargs):\n",
    "        if(num_classes == 0 or input_length == 0):\n",
    "            raise Exception('ModelDimensionException')\n",
    "        super(SimpleFeedForwardNetwork15, self).__init__(**kwargs)\n",
    "        self.dense_1 = tf.keras.layers.Dense(input_length, activation='relu', name='layer1')\n",
    "        self.dense_2 = tf.keras.layers.Dense(2048, activation='relu', name='layer2')\n",
    "        self.dense_3 = tf.keras.layers.Dense(1024, activation='relu', name='layer3')\n",
    "        self.dense_4 = tf.keras.layers.Dense(512, activation='relu', name='layer4')\n",
    "        self.dense_5 = tf.keras.layers.Dense(num_classes, activation='softmax', name='layer5')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        x = self.dense_2(x)\n",
    "        x = self.dense_3(x)\n",
    "        x = self.dense_4(x)\n",
    "        return self.dense_5(x)\n",
    "\n",
    "class Simple1DConvNet(tf.keras.Model):\n",
    "    def __init__(self, num_classes: int = 0, input_dimension=0,\n",
    "                 conv_width: int = 32, batch_input_shape=0, \n",
    "                 **kwargs):\n",
    "        if(num_classes == 0 or input_dimension == 0):\n",
    "            raise Exception('ModelDimensionException')\n",
    "        super(Simple1DConvNet, self).__init__(**kwargs)\n",
    "        self.conv_1 = tf.keras.layers.Conv1D(32, conv_width, padding='same', \n",
    "                                             input_shape=input_dimension[1:],\n",
    "                                             activation='relu', name='conv1')\n",
    "        self.batch_norm_1 = tf.keras.layers.BatchNormalization(axis=1, name='batch_norm_1')\n",
    "        self.max_pooling_1 = tf.keras.layers.MaxPooling1D(pool_size=(3,), name='max_pooling_1')\n",
    "        self.dropout_1 = tf.keras.layers.Dropout(0.25, name='dropout_1')\n",
    "        \n",
    "        self.conv_2 = tf.keras.layers.Conv1D(64, conv_width, padding='same', strides=2, activation='relu', name='conv2')\n",
    "        self.batch_norm_2 = tf.keras.layers.BatchNormalization(axis=1, name='batch_norm_2')\n",
    "        self.conv_3 = tf.keras.layers.Conv1D(64, conv_width, padding='same', strides=2, activation='relu', name='conv3')\n",
    "        self.batch_norm_3 = tf.keras.layers.BatchNormalization(axis=1, name='batch_norm_3')\n",
    "        self.max_pooling_2 = tf.keras.layers.MaxPooling1D(pool_size=(2,), name='max_pooling_2')\n",
    "        self.dropout_2 = tf.keras.layers.Dropout(0.25, name='dropout_2')\n",
    "        \n",
    "        self.conv_4 = tf.keras.layers.Conv1D(128, conv_width, padding='same', strides=2, activation='relu', name='conv4')\n",
    "        self.batch_norm_4 = tf.keras.layers.BatchNormalization(axis=1, name='batch_norm_4')\n",
    "        self.conv_5 = tf.keras.layers.Conv1D(128, conv_width, padding='same', strides=2, activation='relu', name='conv5')\n",
    "        self.batch_norm_5 = tf.keras.layers.BatchNormalization(axis=1, name='batch_norm_5')\n",
    "        self.max_pooling_3 = tf.keras.layers.MaxPooling1D(pool_size=(2,), name='max_pooling_3')\n",
    "        self.dropout_3 = tf.keras.layers.Dropout(0.25, name='dropout_3')\n",
    "        \n",
    "        self.flatten_1 = tf.keras.layers.Flatten(name='flatten_1')\n",
    "        \n",
    "        self.dense_1 = tf.keras.layers.Dense(2048/2, activation='relu', name='dense_1')\n",
    "        self.batch_norm_6 = tf.keras.layers.BatchNormalization(name='batch_norm_6')\n",
    "        self.dropout_4 = tf.keras.layers.Dropout(0.5, name='dropout_4')\n",
    "        \n",
    "        self.dense_2 = tf.keras.layers.Dense(1024/2, activation='relu', name='dense_2')\n",
    "        self.batch_norm_7 = tf.keras.layers.BatchNormalization(name='batch_norm_7')\n",
    "        self.dropout_5 = tf.keras.layers.Dropout(0.5, name='dropout_5')\n",
    "        \n",
    "        self.dense_3 = tf.keras.layers.Dense(num_classes, activation='softmax', name='dense_3')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.conv_1(inputs)\n",
    "        x = self.batch_norm_1(x)\n",
    "        x = self.max_pooling_1(x)\n",
    "        x = self.dropout_1(x)\n",
    "        \n",
    "        x = self.conv_2(x)\n",
    "        x = self.batch_norm_2(x)\n",
    "        x = self.conv_3(x)\n",
    "        x = self.batch_norm_3(x)\n",
    "        x = self.max_pooling_2(x)\n",
    "        x = self.dropout_2(x)\n",
    "        \n",
    "        x = self.conv_4(x)\n",
    "        x = self.batch_norm_4(x)\n",
    "        x = self.conv_5(x)\n",
    "        x = self.batch_norm_5(x)\n",
    "        x = self.max_pooling_3(x)\n",
    "        x = self.dropout_3(x)\n",
    "        \n",
    "        x = self.flatten_1(x)\n",
    "        \n",
    "        x = self.dense_1(x)\n",
    "        x = self.batch_norm_6(x)\n",
    "        x = self.dropout_4(x)\n",
    "        \n",
    "        x = self.dense_2(x)\n",
    "        x = self.batch_norm_7(x)\n",
    "        x = self.dropout_5(x)\n",
    "        \n",
    "        x = self.dense_3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
