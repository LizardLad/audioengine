{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp utils.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import os, sys\n",
    "import inspect\n",
    "import logging\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from typing import Any, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEBUG = os.environ.get('GITHUB_ACTIONS', False) or os.environ.get('AUDIOENGINE_DEBUG', False)\n",
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object attribute util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def recursive_get_size(obj: Any, seen: Union[None, set] = None) -> int:\n",
    "    '''\n",
    "    Get the size of an object in memory recursivly\n",
    "    \n",
    "    Inputs:\n",
    "        param: obj |Any| (Any python object)\n",
    "        kwarg: seen |set| (A set of ids of python objects already seen by the function. This should not be done manually)\n",
    "    Outputs:\n",
    "        return: size |int| (The size of the object in memory measured in bytes)\n",
    "    '''\n",
    "    size = sys.getsizeof(obj)\n",
    "    seen = (set() if seen is None else seen)\n",
    "    if(id(obj) in seen): return 0 #In the case of a self reference\n",
    "    else: pass\n",
    "    seen.add(id(obj))\n",
    "    if(isinstance(obj, dict)):\n",
    "        size += sum([recursive_get_size(v, seen=seen) for v in obj.values()])\n",
    "        size += sum([recursive_get_size(k ,seen=seen) for k in obj.keys()])\n",
    "    elif(hasattr(obj, '__dict__')):\n",
    "        size += recursive_get_size(obj.__dict__, seen)\n",
    "    elif(hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray))):\n",
    "        size += sum([recursive_get_size(i, seen) for i in obj])\n",
    "    return size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def log_init(log_filepath: str = '', log_level: str = '', clear_existing_log: bool = False):\n",
    "    '''\n",
    "    Init the logging module and set up where to log to. When no kwargs are passed the function will check the \n",
    "    environment variable AUDIOENGINE_CONF_JSON for a path to a file to log to. If it doesn't exist then the default\n",
    "    will be grabbed from /project/Development/ML/audio/config/audioengine.conf. If it isn't in there then it will\n",
    "    log to console. It also sets what level is written to the logs. The options are \n",
    "    [debug, info, warning, error, critical] this argument is case insensitive.\n",
    "    \n",
    "    Inputs:\n",
    "        kwarg: log_filepath |str| (Optional filepath to log to)\n",
    "        kwarg: log_level |str| (Optional level of log sensitivity)\n",
    "        kwarg: clear_existing_log |bool| (Optional overwrite existing file or just append. True will overwrite.) \n",
    "    Outputs:\n",
    "        If the filepath to the log file doesn't exist it will be created and opened\n",
    "    '''\n",
    "    config_filepath = os.environ.get('AUDIOENGINE_CONF_JSON', '/project/Development/ML/audio/config/audioengine.conf')\n",
    "    if(os.path.isfile(config_filepath)):\n",
    "        config_fp = open(config_filepath, 'r')\n",
    "        config_str = config_fp.read()\n",
    "        config_fp.close()\n",
    "    else:\n",
    "        config_str = ''\n",
    "    config_json = json.loads(config_str)\n",
    "    logging_options_json = config_json.get('logging', None)\n",
    "    if(logging_options_json is not None and (log_filepath == '' or log_level == '')):\n",
    "        if(log_level == ''):\n",
    "            log_level = logging_options_json.get('log_level')\n",
    "        else:\n",
    "            pass\n",
    "        if(log_filepath == ''):\n",
    "            log_filepath = logging_options_json.get('log_file')\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        if(log_level == ''):\n",
    "            log_level = 'warning'\n",
    "        else:\n",
    "            pass\n",
    "        #Don't do anything for the filepath because it needs to log to console\n",
    "        \n",
    "    filemode = ('w' if clear_existing_log else 'a')\n",
    "    \n",
    "    if(log_level.lower() == 'debug'):\n",
    "        if(log_filepath == ''):\n",
    "            logging.basicConfig(level=logging.DEBUG, filemode=filemode)\n",
    "        else:\n",
    "            logging.basicConfig(level=logging.DEBUG, filename=log_filepath, filemode=filemode)\n",
    "    elif(log_level.lower() == 'info'):\n",
    "        if(log_filepath == ''):\n",
    "            logging.basicConfig(level=logging.INFO, filemode=filemode)\n",
    "        else:\n",
    "            logging.basicConfig(level=logging.INFO, filename=log_filepath, filemode=filemode)\n",
    "    elif(log_level.lower() == 'warning'):\n",
    "        if(log_filepath == ''):\n",
    "            logging.basicConfig(level=logging.WARNING, filemode=filemode)\n",
    "        else:\n",
    "            logging.basicConfig(level=logging.WARNING, filename=log_filepath, filemode=filemode)\n",
    "    elif(log_level.lower() == 'error'):\n",
    "        if(log_filepath == ''):\n",
    "            logging.basicConfig(level=logging.ERROR, filemode=filemode)\n",
    "        else:\n",
    "            logging.basicConfig(level=logging.ERROR, filename=log_filepath, filemode=filemode)\n",
    "    elif(log_level.lower() == 'critical'):\n",
    "        if(log_filepath == ''):\n",
    "            logging.basicConfig(level=logging.CRITICAL, filemode=filemode)\n",
    "        else:\n",
    "            logging.basicConfig(level=logging.CRITICAL, filename=log_filepath, filemode=filemode)\n",
    "    else:\n",
    "        #The log_level wasn't matched\n",
    "        logging.basicConfig(level=logging.WARNING)\n",
    "    log_location = ('console' if log_filepath == '' else 'file: {}'.format(log_filepath))\n",
    "    print('[INFO] Logging now set to {} with level {}'.format(log_location, log_level.upper()))\n",
    "        \n",
    "\n",
    "def log_critical(message: str, exc_info: bool = False):\n",
    "    '''\n",
    "    Log a critical event to the current log and optionally include a traceback\n",
    "    \n",
    "    Inputs:\n",
    "        param: message |str| (The message to print to the log)\n",
    "        kwarg: exc_info |bool| (Include the traceback. False won't include the traceback and True will.)\n",
    "    Outputs:\n",
    "        Prints message and a little bit of context info to the log\n",
    "    '''\n",
    "    func = inspect.currentframe().f_back.f_code\n",
    "    # Dump the message + the name of this function to the log.\n",
    "    logging.critical(\"{}: {} in {}:{}\".format(func.co_filename, func.co_name, func.co_firstlineno, message),\n",
    "                     exc_info=exc_info)\n",
    "\n",
    "def log_error(message: str, exc_info: bool = False):\n",
    "    '''\n",
    "    Log a error event to the current log and optionally include a traceback\n",
    "    \n",
    "    Inputs:\n",
    "        param: message |str| (The message to print to the log)\n",
    "        kwarg: exc_info |bool| (Include the traceback. False won't include the traceback and True will.)\n",
    "    Outputs:\n",
    "        Prints message and a little bit of context info to the log\n",
    "    '''\n",
    "    func = inspect.currentframe().f_back.f_code\n",
    "    # Dump the message + the name of this function to the log.\n",
    "    logging.error(\"{}: {} in {}:{}\".format(func.co_filename, func.co_name, func.co_firstlineno, message),\n",
    "                  exc_info=exc_info)\n",
    "    \n",
    "def log_warning(message: str):\n",
    "    '''\n",
    "    Log a warning event to the current log and optionally include a traceback\n",
    "    \n",
    "    Inputs:\n",
    "        param: message |str| (The message to print to the log)\n",
    "    Outputs:\n",
    "        Prints message and a little bit of context info to the log\n",
    "    '''\n",
    "    func = inspect.currentframe().f_back.f_code\n",
    "    # Dump the message + the name of this function to the log.\n",
    "    logging.warning(\"{}: {} in {}:{}\".format(func.co_filename, func.co_name, func.co_firstlineno, message))    \n",
    "    \n",
    "def log_info(message: str):\n",
    "    '''\n",
    "    Log a info event to the current log and optionally include a traceback\n",
    "    \n",
    "    Inputs:\n",
    "        param: message |str| (The message to print to the log)\n",
    "    Outputs:\n",
    "        Prints message and a little bit of context info to the log\n",
    "    '''\n",
    "    func = inspect.currentframe().f_back.f_code\n",
    "    # Dump the message + the name of this function to the log.\n",
    "    logging.info(\"{}: {} in {}:{}\".format(func.co_filename, func.co_name, func.co_firstlineno, message))\n",
    "    \n",
    "def log_debug(message: str):\n",
    "    '''\n",
    "    Log a debug event to the current log and optionally include a traceback\n",
    "    \n",
    "    Inputs:\n",
    "        param: message |str| (The message to print to the log)\n",
    "    Outputs:\n",
    "        Prints message and a little bit of context info to the log\n",
    "    '''\n",
    "    func = inspect.currentframe().f_back.f_code\n",
    "    # Dump the message + the name of this function to the log.\n",
    "    logging.debug(\"{}: {} in {}:{}\".format(func.co_filename, func.co_name, func.co_firstlineno, message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    #log_init()\n",
    "    log_init(clear_existing_log=True)\n",
    "    log_critical('Critical test')\n",
    "    log_error('Error test')\n",
    "    log_warning('Warning test')\n",
    "    log_info('Info test')\n",
    "    log_debug('Debug test')\n",
    "    \n",
    "    try:\n",
    "        a = 2 / 0\n",
    "    except Exception as exception:\n",
    "        log_critical('Exception raised', exc_info=True)\n",
    "        \n",
    "    try:\n",
    "        a = 2 / 0\n",
    "    except Exception as exception:\n",
    "        log_error('Exception raised', exc_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def get_json_file_integrity(original_json: dict, filepath: str) -> bool:\n",
    "    '''\n",
    "    Load the file from disk and check that it matches the original json that was written to the disk to check that\n",
    "    the file was written without error\n",
    "    \n",
    "    Inputs:\n",
    "        param: original_json |dict| (The json dictionary that was written to disk)\n",
    "        param: filepath |str| (The filepath to where the json dictionary was written)\n",
    "    Outputs:\n",
    "        return: valid |bool| (True if the file matches the json written to it and False otherwise)\n",
    "    '''\n",
    "    json_file = open(filepath, 'r')\n",
    "    json_from_disk = json.loads(json_file.read())\n",
    "    json_file.close()\n",
    "    if(original_json == json_from_disk):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def change_file_extension(filename: str, extension: str) -> str:\n",
    "    '''\n",
    "    Strip the last characters before the last dot and append the new extension to the filename\n",
    "    \n",
    "    Inputs:\n",
    "        param: filename |str| (The current filename with the old extension)\n",
    "        param: extension |str| (The new extension to be put on the string)\n",
    "    Outputs:\n",
    "        return: new_filename |str| (The filename with the new extension)\n",
    "    '''\n",
    "    filename_split = filename.split('.')\n",
    "    filename_split.pop(len(filename_split)-1)\n",
    "    new_filename = '.'.join(filename_split) + extension\n",
    "    return new_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def pad_up_to(t, max_in_dims, constant_values):\n",
    "    s = tf.shape(t)\n",
    "    paddings = [[0, m-s[i]] for (i,m) in enumerate(max_in_dims)]\n",
    "    return tf.pad(t, paddings, 'CONSTANT', constant_values=constant_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
