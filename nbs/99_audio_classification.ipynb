{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp audio_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-23 15:56:08.932628: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import audioengine\n",
    "from audioengine.utils.gpu import list_all_gpus, set_gpu_list_memory_limit\n",
    "from audioengine.utils.schema import verify_audioengine_dataset, verify_audioengine_internal_audio_representation_schema\n",
    "from audioengine.utils.misc import log_init, log_info, log_debug, log_error, pad_up_to\n",
    "from audioengine.models import Simple1DConvNet\n",
    "from audioengine.utils.wav_utils import get_max_samples_in_wav_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Logging now set to file: /project/Development/ML/audio/logs/audioengine.log with level DEBUG\n"
     ]
    }
   ],
   "source": [
    "if(DEBUG == True):\n",
    "    #physical_gpus_list = list_all_gpus()\n",
    "    #set_gpu_list_memory_limit(physical_gpus_list, limit=(2**13+2**11)) #8192\n",
    "    log_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset\n",
    "\n",
    "This notebook will be using the single word dataset which is a subset of the common voice dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIRECTORY = '/project/Datasets/audioengine_single_word'\n",
    "DATASET_NAME = 'train.json'\n",
    "VALIDATION_DATASET_NAME = 'val.json'\n",
    "AUDIO_CLIPS_DIR_NAME = 'clips'\n",
    "\n",
    "DATASET_JSON_FILEPATH = os.path.join(DATASET_DIRECTORY, DATASET_NAME)\n",
    "VALIDATION_DATASET_JSON_FILEPATH = os.path.join(DATASET_DIRECTORY, VALIDATION_DATASET_NAME)\n",
    "AUDIO_CLIPS_FULL_DIR_PATH = os.path.join(DATASET_DIRECTORY, AUDIO_CLIPS_DIR_NAME)\n",
    "\n",
    "dataset_json_fp = open(DATASET_JSON_FILEPATH, 'r')\n",
    "dataset_json = json.load(dataset_json_fp)\n",
    "dataset_json_fp.close()\n",
    "\n",
    "validation_dataset_json_fp = open(VALIDATION_DATASET_JSON_FILEPATH, 'r')\n",
    "validation_dataset_json = json.load(validation_dataset_json_fp)\n",
    "validation_dataset_json_fp.close()\n",
    "\n",
    "if(not verify_audioengine_dataset(dataset_json)):\n",
    "    log_critical('The dataset does not match the schema!')\n",
    "else:\n",
    "    log_debug('The dataset matches the schema')\n",
    "    \n",
    "def create_ir_json(partial_json: dict, audio_clip_directory: str, length_to_pad_to: int) -> dict:\n",
    "    audio_data_id = partial_json['id']\n",
    "    file_name = partial_json['file_name']\n",
    "    full_audio_clip_filepath = os.path.join(audio_clip_directory, file_name)\n",
    "    contents = tf.io.read_file(full_audio_clip_filepath)\n",
    "    audio_data, _ = tf.audio.decode_wav(contents)\n",
    "    audio_data = tf.squeeze(audio_data, axis=1)\n",
    "    audio_data = pad_up_to(audio_data, (length_to_pad_to,), 0)\n",
    "    audio_data = tf.expand_dims(audio_data, axis=-1)\n",
    "\n",
    "\n",
    "    ir_record_json = {'audio_data': audio_data,\n",
    "                      'length': tf.shape(audio_data)[0],\n",
    "                      'id': audio_data_id,\n",
    "                      'file_name': file_name,\n",
    "                      'category_id': partial_json['category_id']\n",
    "                     }\n",
    "    return ir_record_json\n",
    "\n",
    "def convert_labels_list_to_tensor(label_list):\n",
    "    label_tensor = tf.cast(tf.convert_to_tensor(label_list), tf.float32)\n",
    "    one_tensor = tf.constant(1, dtype=tf.float32)\n",
    "    return tf.cast(label_tensor - one_tensor, tf.int32)\n",
    "\n",
    "def convert_classification_audioengine_dataset_to_IR_generator(dataset_json: dict = {}, audio_clip_directory: str = '',\n",
    "                                                               batch_size: int = 256) -> list:\n",
    "    '''\n",
    "    This uses too much memory to hold the whole dataset at once\n",
    "    Need to use generators instead.\n",
    "    '''\n",
    "    #Really needs multiprocessing in the future\n",
    "    if(not dataset_json['info']['task'] == 'classification'):\n",
    "        log_critical('Dataset not using classification task')\n",
    "    else:\n",
    "        log_debug('Dataset using classification task')\n",
    "    \n",
    "    audio_dataset_section_json = dataset_json['audio']\n",
    "    \n",
    "    #Batch it here\n",
    "    num_batches = math.floor((len(audio_dataset_section_json) - (len(audio_dataset_section_json) % batch_size)) / batch_size)\n",
    "    left_over = len(audio_dataset_section_json) % batch_size\n",
    "    \n",
    "    #ir_list = []\n",
    "    max_length = get_max_samples_in_wav_from_directory(audio_clip_directory)\n",
    "    for i in range(num_batches):\n",
    "        batch_ir_list = []\n",
    "        batch_features_list = []\n",
    "        batch_labels_list = []\n",
    "        for j in range(batch_size):\n",
    "            partial_json = audio_dataset_section_json[(i*batch_size)+j]\n",
    "            ir_record_json = create_ir_json(partial_json, audio_clip_directory, max_length)\n",
    "            batch_labels_list.append(ir_record_json['category_id'])\n",
    "            batch_features_list.append(ir_record_json['audio_data'])\n",
    "            batch_ir_list.append(ir_record_json.copy())\n",
    "        batch_features_tensor = tf.cast(tf.stack(batch_features_list, axis=0), tf.float32)\n",
    "        batch_labels_tensor = tf.cast(convert_labels_list_to_tensor(batch_labels_list), tf.int32)\n",
    "        #yield (batch_ir_list, batch_features_tensor, batch_labels_tensor)\n",
    "        yield (batch_features_tensor, batch_labels_tensor)\n",
    "    #if(left_over):\n",
    "    #    partial_json_list = audio_dataset_section_json[-1:-left_over]\n",
    "    #    batch_ir_list = []\n",
    "    #    batch_features_list = []\n",
    "    #    batch_labels_list = []\n",
    "    #    for idx, partial_json in enumerate(partial_json_list):\n",
    "    #        ir_record_json = create_ir_json(partial_json, audio_clip_directory, max_length)\n",
    "    #        batch_labels_list.append(ir_record_json['category_id'])\n",
    "    #        batch_features_list.append(ir_record_json['audio_data'])\n",
    "    #        batch_ir_list.append(ir_record_json.copy())\n",
    "    #    batch_features_tensor = tf.cast(tf.stack(batch_features_list, axis=0), tf.float32)\n",
    "    #    batch_labels_tensor = tf.cast(convert_labels_list_to_tensor(batch_labels_list), tf.int32)\n",
    "    #    #yield (batch_ir_list, batch_features_tensor, batch_labels_tensor)\n",
    "    #    yield (batch_features_tensor, batch_labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-23 15:56:11.751642: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-23 15:56:11.835057: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-23 15:56:11.835599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:09:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-07-23 15:56:11.835616: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-23 15:56:11.837741: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-23 15:56:11.837782: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-23 15:56:11.838475: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-23 15:56:11.838630: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-23 15:56:11.840703: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-07-23 15:56:11.841179: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-23 15:56:11.841267: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-23 15:56:11.841365: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-23 15:56:11.841936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-23 15:56:11.842420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-07-23 15:56:11.842760: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-23 15:56:11.843575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-23 15:56:11.844741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:09:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-07-23 15:56:11.844858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-23 15:56:11.846063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-23 15:56:11.847175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-07-23 15:56:11.847232: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-23 15:56:12.215642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-23 15:56:12.215678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-07-23 15:56:12.215685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-07-23 15:56:12.215861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-23 15:56:12.216408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-23 15:56:12.216924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-23 15:56:12.217421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10417 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1)\n",
      "2021-07-23 15:56:12.474410: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-07-23 15:56:12.491581: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3393665000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-23 15:56:13.987506: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-23 15:56:14.197499: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101\n",
      "2021-07-23 15:56:14.397628: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-23 15:56:14.564929: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-23 15:56:14.671829: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.31GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-07-23 15:56:14.732139: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.31GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2757/2757 [==============================] - 1926s 698ms/step - loss: 2.7375 - accuracy: 0.1905 - val_loss: 30.5246 - val_accuracy: 0.0775\n",
      "Epoch 2/256\n",
      "2757/2757 [==============================] - 1932s 701ms/step - loss: 1.8049 - accuracy: 0.3779 - val_loss: 6.9333 - val_accuracy: 0.2100\n",
      "Epoch 3/256\n",
      "2757/2757 [==============================] - 1933s 701ms/step - loss: 1.5135 - accuracy: 0.4904 - val_loss: 7.4711 - val_accuracy: 0.2271\n",
      "Epoch 4/256\n",
      "2757/2757 [==============================] - 1934s 701ms/step - loss: 1.2929 - accuracy: 0.5716 - val_loss: 4.9516 - val_accuracy: 0.4647\n",
      "Epoch 5/256\n",
      "2757/2757 [==============================] - 1933s 701ms/step - loss: 1.1092 - accuracy: 0.6334 - val_loss: 8.3304 - val_accuracy: 0.5959\n",
      "Epoch 6/256\n",
      "2757/2757 [==============================] - 1932s 701ms/step - loss: 0.8899 - accuracy: 0.7161 - val_loss: 15.6803 - val_accuracy: 0.5127\n",
      "Epoch 8/256\n",
      "2757/2757 [==============================] - 1934s 701ms/step - loss: 0.8209 - accuracy: 0.7402 - val_loss: 3.9438 - val_accuracy: 0.6455\n",
      "Epoch 9/256\n",
      "2757/2757 [==============================] - 1936s 702ms/step - loss: 0.7538 - accuracy: 0.7614 - val_loss: 10.2809 - val_accuracy: 0.6641\n",
      "Epoch 10/256\n",
      "2757/2757 [==============================] - 1938s 703ms/step - loss: 0.7117 - accuracy: 0.7730 - val_loss: 4.7700 - val_accuracy: 0.5265\n",
      "Epoch 11/256\n",
      "2757/2757 [==============================] - 1938s 703ms/step - loss: 0.6485 - accuracy: 0.7960 - val_loss: 7.8449 - val_accuracy: 0.5259\n",
      "Epoch 12/256\n",
      "2757/2757 [==============================] - 1940s 704ms/step - loss: 0.6044 - accuracy: 0.8097 - val_loss: 22.7405 - val_accuracy: 0.2968\n",
      "Epoch 13/256\n",
      "2757/2757 [==============================] - 1940s 704ms/step - loss: 0.5623 - accuracy: 0.8226 - val_loss: 5.7398 - val_accuracy: 0.5948\n",
      "Epoch 14/256\n",
      "2757/2757 [==============================] - 1940s 704ms/step - loss: 0.5301 - accuracy: 0.8335 - val_loss: 6.9317 - val_accuracy: 0.6743\n",
      "Epoch 15/256\n",
      "2757/2757 [==============================] - 1940s 704ms/step - loss: 0.5027 - accuracy: 0.8419 - val_loss: 8.3127 - val_accuracy: 0.6998\n",
      "Epoch 16/256\n",
      "2757/2757 [==============================] - 1942s 705ms/step - loss: 0.4741 - accuracy: 0.8508 - val_loss: 10.7977 - val_accuracy: 0.7131\n",
      "Epoch 17/256\n",
      " 337/2757 [==>...........................] - ETA: 22:50 - loss: 0.4541 - accuracy: 0.8479"
     ]
    }
   ],
   "source": [
    "#Construct the dataset\n",
    "BATCH_SIZE = 8\n",
    "VALIDATION_BATCH_SIZE = 8\n",
    "EPOCHS_COUNT = 256\n",
    "\n",
    "#Get more information about the dataset\n",
    "num_classes = len(dataset_json['categories'])\n",
    "max_length = get_max_samples_in_wav_from_directory(AUDIO_CLIPS_FULL_DIR_PATH)\n",
    "input_dimension = (BATCH_SIZE, max_length, 1)\n",
    "\n",
    "validation_input_dimension = (VALIDATION_BATCH_SIZE, max_length, 1)\n",
    "validation_label_shape = (VALIDATION_BATCH_SIZE, )\n",
    "\n",
    "    \n",
    "#setup model\n",
    "model = Simple1DConvNet(num_classes=num_classes, \n",
    "                        input_dimension=input_dimension, \n",
    "                        batch_input_shape=input_dimension)\n",
    "\n",
    "# setup loss and optimizer\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1.0,\n",
    "                                                          decay_steps=10000,\n",
    "                                                          decay_rate=0.9)\n",
    "optimizer = tf.keras.optimizers.Adadelta(learning_rate=lr_schedule)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "def train_model(model, dataset_generator, validation_dataset: tf.data.Dataset, \n",
    "                num_epochs: int = 0, \n",
    "                log_step_count: int = 200, dataset_json: dict = {},\n",
    "                audio_clip_directory: str = '', batch_size: int = 8,\n",
    "                batch_input_dimension: tuple = (),\n",
    "                label_tensor_shape: tuple = (),\n",
    "                callbacks: list = []):\n",
    "    generator_partial = functools.partial(dataset_generator, dataset_json=dataset_json, \n",
    "                                          audio_clip_directory=audio_clip_directory, batch_size=batch_size)\n",
    "    dataset = tf.data.Dataset.from_generator(generator_partial, output_signature=(tf.TensorSpec(shape=batch_input_dimension, dtype=tf.float32),\n",
    "                                                                                  tf.TensorSpec(shape=label_tensor_shape, dtype=tf.int32)))\n",
    "    model.fit(x=dataset, epochs=num_epochs, callbacks=callbacks, validation_data=validation_dataset)\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True)\n",
    "    \n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "validation_data_generator_partial = functools.partial(convert_classification_audioengine_dataset_to_IR_generator, \n",
    "                                                      dataset_json=validation_dataset_json, \n",
    "                                                      audio_clip_directory=AUDIO_CLIPS_FULL_DIR_PATH, \n",
    "                                                      batch_size=VALIDATION_BATCH_SIZE)\n",
    "validation_dataset = tf.data.Dataset.from_generator(validation_data_generator_partial, \n",
    "                                                    output_signature=(tf.TensorSpec(shape=validation_input_dimension, dtype=tf.float32),\n",
    "                                                    tf.TensorSpec(shape=validation_label_shape, dtype=tf.int32)))\n",
    "\n",
    "train_model(model, convert_classification_audioengine_dataset_to_IR_generator, validation_dataset,\n",
    "              num_epochs=EPOCHS_COUNT, log_step_count=1, \n",
    "              dataset_json=dataset_json, \n",
    "              audio_clip_directory=AUDIO_CLIPS_FULL_DIR_PATH,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              batch_input_dimension=input_dimension,\n",
    "              label_tensor_shape=(BATCH_SIZE,),\n",
    "              callbacks = [early_stopping_callback])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnn_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
